.. note::

    Hola, ¬°bienvenido a la comunidad de entusiastas de SunFounder Raspberry Pi & Arduino & ESP32 en Facebook! Sum√©rgete a√∫n m√°s en el mundo de Raspberry Pi, Arduino y ESP32 con otros apasionados.

    **¬øPor qu√© unirse?**

    - **Soporte de Expertos**: Resuelve problemas post-venta y desaf√≠os t√©cnicos con la ayuda de nuestra comunidad y equipo.
    - **Aprende y Comparte**: Intercambia consejos y tutoriales para mejorar tus habilidades.
    - **Avances Exclusivos**: Obt√©n acceso anticipado a los anuncios de nuevos productos y a vistas previas.
    - **Descuentos Especiales**: Disfruta de descuentos exclusivos en nuestros productos m√°s recientes.
    - **Promociones y Sorteos Festivos**: Participa en sorteos y promociones especiales durante las festividades.

    üëâ ¬øListo para explorar y crear con nosotros? Haz clic en [|link_sf_facebook|] y √∫nete hoy mismo.

.. _ai_voice_assistant_robot:

20. Perro Asistente de Voz con IA
=========================================

Esta lecci√≥n transforma tu Pidog en un **perro asistente de voz impulsado por IA** üê∂.  
El robot puede activarse con tu voz, entender lo que dices, responder con personalidad  
y expresar sus ‚Äúsentimientos‚Äù a trav√©s de movimientos, gestos y efectos de iluminaci√≥n LED.

Construir√°s un **compa√±ero rob√≥tico totalmente interactivo** usando:

* **LLM**: Modelo de Lenguaje Extenso (por ejemplo, OpenAI GPT o Doubao) para conversaciones naturales.  
* **STT**: Voz a Texto para reconocimiento de voz.  
* **TTS**: Texto a Voz para respuestas vocales expresivas.  
* **Sensores + Acciones**: Sensor ultras√≥nico, visi√≥n por c√°mara (opcional), sensores t√°ctiles y movimientos expresivos incorporados.

----

Antes de Comenzar
--------------------

Aseg√∫rate de haber completado:

* :ref:`install_all_modules` ‚Äî Instalar los m√≥dulos ``robot-hat``, ``vilib``, ``pidog`` y luego ejecutar el script ``i2samp.sh``.
* :ref:`test_piper` ‚Äî Comprobar los idiomas compatibles de **Piper TTS**.  
* :ref:`test_vosk` ‚Äî Comprobar los idiomas compatibles de **Vosk STT**.  
* :ref:`py_online_llm` ‚Äî Este paso es **muy importante**: obtener tu clave de API de **OpenAI** o **Doubao**, o la clave de API de cualquier otro LLM compatible.

Ya deber√≠as tener:

* Un **micr√≥fono** y **altavoz** funcionando en tu Pidog.  
* Una **clave de API v√°lida** guardada en ``secret.py``.  
* Una conexi√≥n de red estable (se recomienda una **conexi√≥n por cable** para mayor estabilidad).

----

Ejecutar el Ejemplo
-----------------------------

Ambas versiones de idioma est√°n ubicadas en el mismo directorio:

.. code-block:: bash

   cd ~/pidog/examples

**Versi√≥n en ingl√©s** (OpenAI GPT, instrucciones en ingl√©s):

.. code-block:: bash

   sudo python3 20_voice_active_dog_gpt.py

* LLM: ``OpenAI GPT-4o-mini``  
* TTS: ``en_US-ryan-low`` (Piper)  
* STT: Vosk (``en-us``)

Palabra de activaci√≥n:

.. code-block::

   "Hey buddy"


---
**Versi√≥n en chino** (Doubao, instrucciones en chino):

.. code-block:: bash

   sudo python3 20_voice_active_dog_doubao_cn.py

* LLM: ``Doubao-seed-1-6-250615``  
* TTS: ``zh_CN-huayan-x_low`` (Piper)  
* STT: Vosk (``cn``)

Palabra de activaci√≥n:

.. code-block::

   "‰Ω†Â•Ω Êó∫Ë¥¢"

.. note::

   Puedes modificar la **palabra de activaci√≥n** y el **nombre del robot** en el c√≥digo:
   ``NAME = "Buddy"`` o ``NAME = "Êó∫Ë¥¢"``  
   ``WAKE_WORD = ["hey buddy"]`` o ``WAKE_WORD = ["‰Ω†Â•Ω Êó∫Ë¥¢"]``

----

Qu√© Suceder√°
-----------------

Cuando ejecutes este ejemplo correctamente:

* El robot **espera la palabra de activaci√≥n** (por ejemplo, ‚ÄúHey Buddy‚ÄùÔºå‚Äú‰Ω†Â•Ω Êó∫Ë¥¢‚Äù).  
* Cuando escucha la palabra de activaci√≥n:

  * La tira LED se vuelve **rosa (respiraci√≥n)** como se√±al de activaci√≥n.  
  * El robot te saluda con la respuesta de activaci√≥n establecida ‚Äî  
    por ejemplo, ‚Äú¬°Hola!‚Äù (a trav√©s de Piper TTS).

* Luego comienza a **escuchar tu voz** mediante Vosk STT (o acepta entrada por teclado si est√° habilitado).  

* Despu√©s de reconocer lo que dijiste, el sistema:

  * Captura un **fotograma de la c√°mara** (porque ``WITH_IMAGE = True``) y env√≠a tu mensaje + imagen al **LLM** (OpenAI ``gpt-4o-mini``).  
  * El LED cambia a **amarillo (escuchando/procesando)** mientras el modelo piensa.  
  * La respuesta del modelo se divide en dos partes:

    - Texto antes de ``ACTIONS:`` ‚Üí se pronuncia en voz alta.  
    - Palabras clave despu√©s de ``ACTIONS:`` ‚Üí se asignan a movimientos del robot.

  * El robot **ejecuta esas acciones** a trav√©s de ``ActionFlow``.  
  * Cuando las acciones terminan, el robot **vuelve a la postura SENTADO (SIT)** y apaga los LEDs.

* Si el **sensor ultras√≥nico detecta un obst√°culo** a menos de 10 cm:

  - Se inyecta un mensaje: ``<<<Ultrasonic sense too close: {distance}cm>>>``  
  - El robot retrocede autom√°ticamente: ``ACTIONS: backward``  
  - **La entrada de imagen se desactiva** para esta ronda.

* Si se **activa el sensor t√°ctil**:

  - Para un toque de **GUSTO** (por ejemplo, FRONT_TO_REAR):

    - Se inyecta: ``<<<Touch style you like: FRONT_TO_REAR>>>``  
    - ``ACTIONS: nod`` (respuesta positiva)

  - Para un toque de **DESAGRADO** (por ejemplo, REAR_TO_FRONT):

    - Se inyecta: ``<<<Touch style you hate: REAR_TO_FRONT>>>``  
    - ``ACTIONS: backward`` (reacci√≥n de evasi√≥n)

* **Ciclo de vida de los LEDs:**

  - ``on_start`` ‚Üí postura SENTADO, LEDs apagados  
  - ``before_listen`` ‚Üí cian (listo)  
  - ``before_think`` ‚Üí amarillo (procesando)  
  - ``before_say`` ‚Üí rosa (hablando)  
  - ``after_say`` / ``on_finish_a_round`` ‚Üí postura SENTADO, LEDs apagados  
  - ``on_stop`` ‚Üí detener el flujo de acciones y cerrar dispositivos

**Ejemplo de interacci√≥n**

.. code-block:: text

   You: Hey Buddy
   Robot: Hi there!

   You: What do you see in front of you?
   Robot: I can see a notebook and a blue mug on the table.
   ACTIONS: think

   You: Do a little nod for me.
   Robot: Of course. Watch my majestic nod.
   ACTIONS: nod

   (Front-to-rear touch on the head)
   Robot: Ooooh, that‚Äôs nice!
   ACTIONS: nod

   (Moving too close)
   Robot: Hey hey‚Äîtoo close! Backing up for safety.
   ACTIONS: backward


----

Cambio a Otros LLM o TTS
------------------------------

Puedes cambiar f√°cilmente a otros LLM, TTS o idiomas de STT con solo unos pocos ajustes:

* LLM compatibles:

  * OpenAI
  * Doubao
  * Deepseek
  * Gemini
  * Qwen
  * Grok

* :ref:`test_piper` ‚Äî Comprueba los idiomas compatibles con **Piper TTS**.  
* :ref:`test_vosk` ‚Äî Comprueba los idiomas compatibles con **Vosk STT**.  

Para cambiar, simplemente modifica la parte de inicializaci√≥n en el c√≥digo:

.. code-block:: python

  from pidog.llm import OpenAI as LLM

  llm = LLM(
      api_key=API_KEY,
      model="gpt-4o-mini",
  )

  # Configurar modelos e idiomas
  TTS_MODEL = "en_US-ryan-low"
  STT_LANGUAGE = "en-us"

----

Soluci√≥n de Problemas
------------------------------

* **El robot no responde a la palabra de activaci√≥n**  

  * Verifica si el micr√≥fono funciona.  
  * Aseg√∫rate de que ``WAKE_ENABLE = True``.  
  * Ajusta la palabra de activaci√≥n para que coincida con tu pronunciaci√≥n.

* **No hay sonido en el altavoz**
 
  * Verifica la configuraci√≥n del modelo TTS.  
  * Prueba Piper o Espeak manualmente.  
  * Revisa la conexi√≥n y el volumen del altavoz.

* **Error o tiempo de espera de la clave API** 
 
  * Verifica tu clave en ``secret.py``.  
  * Asegura una conexi√≥n de red estable.  
  * Confirma que el LLM sea compatible.

* **El sensor ultras√≥nico se activa inesperadamente.**  

  * Revisa la altura y el √°ngulo de instalaci√≥n del sensor.  
  * Ajusta el umbral de distancia ``TOO_CLOSE`` en el c√≥digo.
